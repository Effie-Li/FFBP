{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from collections import OrderedDict, namedtuple\n",
    "\n",
    "def extract_tensor_from_summary(summary_value, dt=None):\n",
    "    \"\"\"\n",
    "    De-serializes data from tensorflow event\n",
    "    :param summary_value: event.summary.value object created by summary writer\n",
    "    :return deci_tensor:  decimal numpy array\n",
    "    \"\"\"\n",
    "    _dt = dt if dt else tf.as_dtype(summary_value.tensor.dtype).as_numpy_dtype()\n",
    "    shape = tuple([i.size for i in summary_value.tensor.tensor_shape.dim])\n",
    "    print(shape)\n",
    "    binary_tensor = summary_value.tensor.tensor_content\n",
    "#     print(np.fromstring(binary_tensor, dtype=dt))\n",
    "    deci_tensor = np.fromstring(binary_tensor, dtype=dt).reshape(shape)\n",
    "    return deci_tensor\n",
    "\n",
    "\n",
    "def retrieve_model_params(path_to_event_file, layer_name, param_name):\n",
    "    \"\"\"\n",
    "    Retrieves parameter values from a tensorflow event file and structures it into an ordered dict\n",
    "    :param path_to_event_file: absolute path to event file\n",
    "    :param layer_name: string name of the layer\n",
    "    :param params_summary: stirng name of the parameter to retrieve (e.g. 'weights')\n",
    "    :param data_type (optional): data type of output numpy arrays (if ommited, original data type converted from \n",
    "        tensorflow DType to numpy dtype will be used\n",
    "    :return: params_dict: an ordered dict where keys are global steps (of type int) and values are numpy arrays\n",
    "    \"\"\"\n",
    "    params_dict = OrderedDict()\n",
    "    lookup = (layer_name, param_name)\n",
    "    for event in tf.train.summary_iterator(path_to_event_file):\n",
    "        for val in event.summary.value:\n",
    "            if all([item in val.tag for item in lookup]):\n",
    "                params_dict[event.step] = tf.contrib.util.make_ndarray(val.tensor)\n",
    "    return params_dict\n",
    "\n",
    "\n",
    "def retrieve_model_data(path_to_event_file, layer_name, tensor_name):\n",
    "    data_dict = OrderedDict()\n",
    "    SummaryData = namedtuple('SummaryData', ['labels','inputs','targets','data'])\n",
    "    lookup = '/'.join([layer_name,tensor_name])\n",
    "    for i, event in enumerate(tf.train.summary_iterator(event_file)):\n",
    "        data_dict.setdefault(event.step, SummaryData([],[],[],[]))\n",
    "        for val in event.summary.value:\n",
    "            if 'pattern_labels' in val.tag:\n",
    "                data_dict[event.step].labels.append(val.tensor.string_val[0].decode('utf-8'))\n",
    "            if 'input_patterns' in val.tag:\n",
    "                data_dict[event.step].inputs.append(tf.contrib.util.make_ndarray(val.tensor))\n",
    "            if 'target_patterns' in val.tag:\n",
    "                data_dict[event.step].targets.append(tf.contrib.util.make_ndarray(val.tensor))\n",
    "            if lookup in val.tag:\n",
    "                data_dict[event.step].data.append(tf.contrib.util.make_ndarray(val.tensor))\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def retrieve_loss(path_to_event_file):\n",
    "    eacc = get_event_accumulator(path_to_event_file)\n",
    "    loss_log = np.stack([np.asarray([scalar.step, scalar.value]) for scalar in eacc.Scalars('train/error_summary')])\n",
    "    return loss_log#    \n",
    "\n",
    "\n",
    "def display_model_data(data_dict):\n",
    "    for step, data in data_dict.items():\n",
    "        print('> Epoch',step)\n",
    "        print('  labels:')\n",
    "        for x in data.labels: print(x)\n",
    "        print('  inputs:')\n",
    "        for x in data.inputs: print(x)\n",
    "        print('  targets:')\n",
    "        for x in data.targets: print(x)\n",
    "        print('  data:')\n",
    "        for x in data.data: print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PATH VARS\n",
    "logdir = '/Users/alexten/Projects/pdpyflow/xor/train/log_000'\n",
    "event_file = os.path.join(logdir, os.listdir(logdir)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of all (unique) summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_list = []\n",
    "for event in tf.train.summary_iterator(event_file):\n",
    "    for val in event.summary.value:\n",
    "        tag_list.append(val.tag)\n",
    "for tag in sorted(set(tag_list)):\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get summary by tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = ['output_layer','gradient-weights']\n",
    "for event in tf.train.summary_iterator(event_file):\n",
    "    for val in event.summary.value:\n",
    "        if all([item in val.tag for item in lookup]):\n",
    "            print(event.step)\n",
    "            print(tf.contrib.util.make_ndarray(val.tensor))\n",
    "#             print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch 0\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.01239182 -0.00362648]]]\n",
      "[[[-0.01243565 -0.0035806 ]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.01815801  0.00572924]\n",
      "  [ 0.01815801  0.00572924]]]\n",
      "> Epoch 30\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.00761698  0.00090695]]]\n",
      "[[[-0.00761462  0.00088839]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.00815999 -0.00096241]\n",
      "  [ 0.00815999 -0.00096241]]]\n",
      "> Epoch 60\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.00319089  0.00200099]]]\n",
      "[[[-0.00318931  0.00196098]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.00314384 -0.00194168]\n",
      "  [ 0.00314384 -0.00194168]]]\n",
      "> Epoch 90\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.00114853  0.00278966]]]\n",
      "[[[-0.00114812  0.00273845]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.00111109 -0.00266735]\n",
      "  [ 0.00111109 -0.00266735]]]\n",
      "> Epoch 120\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.00057713  0.00402788]]]\n",
      "[[[-0.00057695  0.00396249]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.0005562  -0.00382913]\n",
      "  [ 0.0005562  -0.00382913]]]\n",
      "> Epoch 150\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.0005678   0.00592953]]]\n",
      "[[[-0.00056763  0.00584972]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.0005465  -0.00557717]\n",
      "  [ 0.0005465  -0.00557717]]]\n",
      "> Epoch 180\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.00070017  0.00905243]]]\n",
      "[[[-0.00070001  0.00896226]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.00067355 -0.00829626]\n",
      "  [ 0.00067355 -0.00829626]]]\n",
      "> Epoch 210\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [-0.00057053  0.01535461]]]\n",
      "[[[-0.00057051  0.01526748]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ 0.0005507  -0.01291347]\n",
      "  [ 0.0005507  -0.01291347]]]\n",
      "> Epoch 240\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [ 0.00256347  0.02991921]]]\n",
      "[[[ 0.00256402  0.02990379]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[-0.00258695 -0.01432337]\n",
      "  [-0.00258695 -0.01432337]]]\n",
      "> Epoch 270\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [ 0.03253076  0.02005007]]]\n",
      "[[[ 0.03247843  0.02001243]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[-0.04943636 -0.00064244]\n",
      "  [-0.04943636 -0.00064244]]]\n",
      "> Epoch 300\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [ 0.01787114  0.00160685]]]\n",
      "[[[ 0.01801061  0.00162076]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ -2.47371327e-02  -4.01118177e-06]\n",
      "  [ -2.47371327e-02  -4.01118177e-06]]]\n",
      "> Epoch 317\n",
      "  labels:\n",
      "p00\n",
      "p01\n",
      "p10\n",
      "p11\n",
      "  inputs:\n",
      "[[ 0.  0.]]\n",
      "[[ 0.  1.]]\n",
      "[[ 1.  0.]]\n",
      "[[ 1.  1.]]\n",
      "  targets:\n",
      "[[ 0.]]\n",
      "[[ 1.]]\n",
      "[[ 1.]]\n",
      "[[ 0.]]\n",
      "  data:\n",
      "[[[ 0.  0.]\n",
      "  [ 0.  0.]]]\n",
      "[[[ 0.          0.        ]\n",
      "  [ 0.00321595  0.00062414]]]\n",
      "[[[ 0.0032035   0.00062443]\n",
      "  [ 0.          0.        ]]]\n",
      "[[[ -4.25328221e-03  -9.08206175e-07]\n",
      "  [ -4.25328221e-03  -9.08206175e-07]]]\n"
     ]
    }
   ],
   "source": [
    "hidden_weights = retrieve_model_params(event_file, 'hidden_layer', 'weights')\n",
    "hidden_bias = retrieve_model_params(event_file, 'hidden_layer', 'bias')\n",
    "hidden_acts = retrieve_model_data(event_file, 'hidden_layer', 'gradient_weights')\n",
    "# print(hidden_acts[0].labels)\n",
    "display_model_data(hidden_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
