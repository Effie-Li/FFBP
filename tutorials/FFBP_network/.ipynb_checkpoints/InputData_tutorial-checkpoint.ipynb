{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building & reading data sets\n",
    "Since the [FFBP package](https://github.com/alex-ten/pdpyflow/tree/master/FFBP) runs [Tensorflow](https://www.tensorflow.org/), you need to make input data readable for the underlying computational graph. FFBP has a special class called `InputData` that lets you easily convert a csv data file into a structure that can be injected into a Tensorflow graph.\n",
    "\n",
    "The csv file must be structured in a certain way (see example below). The very first row is reserved for column labels; it is there for convenience and in effect will be ignored. Each subsequent row contains a labeled input pattern. Each row is organized into a sequence of entries, whereby the first entry contains the pattern label, and the following entries encode the actual input/target data. A sequence of input data comes first, followed by a sequence of target data. The example below is from the training data for this tutorial's 8-3-8 auto-encoder network (note that spaces were added for readability):\n",
    "\n",
    "```\n",
    "inp_label,  input,             target\n",
    "p1,         1,0,0,0,0,0,0,0,   1,0,0,0,0,0,0,0\n",
    "p2,         0,1,0,0,0,0,0,0,   0,1,0,0,0,0,0,0\n",
    "p3,         0,0,1,0,0,0,0,0,   0,0,1,0,0,0,0,0\n",
    "p4,         0,0,0,1,0,0,0,0,   0,0,0,1,0,0,0,0\n",
    "p5,         0,0,0,0,1,0,0,0,   0,0,0,0,1,0,0,0\n",
    "p6,         0,0,0,0,0,1,0,0,   0,0,0,0,0,1,0,0\n",
    "p7,         0,0,0,0,0,0,1,0,   0,0,0,0,0,0,1,0\n",
    "p8,         0,0,0,0,0,0,0,1,   0,0,0,0,0,0,0,1\n",
    "```\n",
    "**Importantly, each row must end with an implicit newline character \"`\\n`\", not a comma \"`,`\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading csv data file\n",
    "It is straightforward to create an `InputData` instance from the data file organized correctly. You need to specify a few parameters to make it work:\n",
    "- **`num_epochs`** : the number of epochs you are planning to train/test the model for. An epoch is a single iteration inside which a network processes the entire data set (typically seeing each pattern exactly once).\n",
    "- **`batch_size`** : the size of a subset (mini-batch) of the data set. Together with `data_len`, this parameter determines the number of weight updates per epoch of training. Specifically, within a single epoch of training, weights will be updated `data_len / batch_size` times. For example, if `batch_size==data_len`, the network will accumulate gradients for each training pattern and perform a weight update once per epoch. In contrast, if `batch_size==1`, each training pattern will cause a weight update, making the order of training examples consequential. Moreover, if `(batch_size>1 & batch_size<data_len)`, several training patterns will cause a weight update and there will be more than one update per epoch. Thus, `batch_size` must divide `data_len`, that is, the remainder of `data_len / batch_size` must be zero.\n",
    "- **`data_len`** : the number of input patterns in the data set. Together with `batch_size`, this parameter determines the number of weight updates per epoch of training (see `batch_size`).\n",
    "- **`inp_size`** : the number of input data points (same as the size of input layer).\n",
    "- **`targ_size`** : the number of target data points (same as the size of output layer).\n",
    "-  **`shuffle_seed`** : (optional, *default*=`None`) the seed for a random number generator that dictates the shuffling of input patterns. If `None`, input patterns will be fed in the same order (top to bottom) as they appear in the csv file. If negative (e.g. `shuffle_seed=-1`), the seed will be generated at random and shuffling will be intractable.\n",
    "\n",
    "In the example below, we set up training and testing data for a training loop simulation. Note that **for testing, we set the `batch_size=DATA_LEN`** to make testing more efficient. This will feed the entire data set in a single batch, but each element of the batch will be processed separately. Also note that we don't want to shuffle testing patterns (so ommit the `shuffle_seed` parameter or set it to `None`).\n",
    "\n",
    "Feel free to change the parameters and observe the effects in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0:\n",
      "\n",
      "  TESTING:\n",
      "    testing pattern 0: 'p1' [ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "    testing pattern 1: 'p2' [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "    testing pattern 2: 'p3' [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "    testing pattern 3: 'p4' [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "    testing pattern 4: 'p5' [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "    testing pattern 5: 'p6' [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "    testing pattern 6: 'p7' [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "    testing pattern 7: 'p8' [ 0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "  TRAINING:\n",
      "    processing mini-batch 1/2: ['p8', 'p5', 'p6', 'p3']\n",
      "\t[[ 0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "\t [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "\t [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "\t [ 0.  0.  1.  0.  0.  0.  0.  0.]]\n",
      "    processing mini-batch 2/2: ['p4', 'p1', 'p7', 'p2']\n",
      "\t[[ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "\t [ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\t [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "\t [ 0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "\n",
      "EPOCH 1:\n",
      "\n",
      "  TESTING:\n",
      "    testing pattern 0: 'p1' [ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "    testing pattern 1: 'p2' [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "    testing pattern 2: 'p3' [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "    testing pattern 3: 'p4' [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "    testing pattern 4: 'p5' [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "    testing pattern 5: 'p6' [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "    testing pattern 6: 'p7' [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "    testing pattern 7: 'p8' [ 0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "  TRAINING:\n",
      "    processing mini-batch 1/2: ['p4', 'p7', 'p5', 'p8']\n",
      "\t[[ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "\t [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "\t [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "\t [ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "    processing mini-batch 2/2: ['p6', 'p3', 'p2', 'p1']\n",
      "\t[[ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "\t [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "\t [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "\t [ 1.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import FFBP\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # Prevent unwanted logging messages by tensorflow\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 4\n",
    "INP_SIZE = 8\n",
    "TARG_SIZE = 8\n",
    "DATA_LEN = 8\n",
    "SHUFFLE = 1\n",
    "\n",
    "FFBP_GRAPH = tf.Graph()\n",
    "\n",
    "with FFBP_GRAPH.as_default():\n",
    "    \n",
    "    # Create data for training\n",
    "    TRAIN_DATA = FFBP.InputData(\n",
    "            path_to_data_file = 'auto_data.txt',\n",
    "            num_epochs = NUM_EPOCHS,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            data_len = DATA_LEN,\n",
    "            inp_size = INP_SIZE, \n",
    "            targ_size = TARG_SIZE,\n",
    "            shuffle_seed = SHUFFLE,\n",
    "        )\n",
    "\n",
    "    # Create data for testing\n",
    "    TEST_DATA = FFBP.InputData(\n",
    "        path_to_data_file = 'auto_data.txt',\n",
    "        num_epochs = NUM_EPOCHS,\n",
    "        batch_size = DATA_LEN,\n",
    "        inp_size = INP_SIZE, \n",
    "        targ_size = TARG_SIZE,\n",
    "        data_len = DATA_LEN,\n",
    "    )\n",
    "\n",
    "# Simulate training loop\n",
    "with tf.Session(graph=FFBP_GRAPH) as sess:\n",
    "        # Initialize variables\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # create coordinator and start queue runners\n",
    "        coordinator = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coordinator)\n",
    "\n",
    "        for i in range(NUM_EPOCHS):\n",
    "            print('\\nEPOCH {}:\\n'.format(i))\n",
    "            \n",
    "            # Mock-test model in a test mini-loop\n",
    "            print('  TESTING:')\n",
    "            test_examples = sess.run(TEST_DATA.examples_batch)\n",
    "            for j, example in enumerate(zip(*test_examples)):\n",
    "                print('    testing pattern {}: \\'{}\\' {}'.format(j, example[0].decode('UTF-8'),example[1]))\n",
    "\n",
    "            # Mock-train model in a train mini-loop\n",
    "            print('  TRAINING:')\n",
    "            num_updates = TRAIN_DATA.data_len // TRAIN_DATA.batch_size\n",
    "            for k in range(num_updates):\n",
    "                examples_batch = sess.run(TRAIN_DATA.examples_batch)\n",
    "                print(\n",
    "                    '    processing mini-batch {}/{}: {}'.format(\n",
    "                        k+1, num_updates, \n",
    "                        [x.decode('UTF-8') for x in examples_batch[0]]\n",
    "                    )\n",
    "                )\n",
    "#                 print('      {}'.format(examples_batch[1]))\n",
    "                print('\\t' + str(examples_batch[1]).replace('\\n', '\\n\\t'))\n",
    "\n",
    "        coordinator.request_stop()\n",
    "        coordinator.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
